{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9c4ffc5e",
   "metadata": {},
   "source": [
    "# SSVEP decoding algorithms\n",
    "\n",
    "In this notebook, we'll take a look at some algorithms for decoding SSVEP responsens.\n",
    "We'll make use of the `SSVEPExo` dataset and some existing state-of-the-art SSVEP decoding algorithms.\n",
    "the dataset and the algorithms are accessed trough MOABB. You will also implement your own decoding algorithm, based on the feature extraction pipeline implemented in the previous notebook.\n",
    "\n",
    "To be able to compare all algorithms, we'll only investigate the trials where stimulation is happening and do not attempt to classify the `rest` state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cc2877c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from moabb.datasets import SSVEPExo\n",
    "\n",
    "dataset = SSVEPExo()\n",
    "dataset.event_id= {\n",
    "    '13': 2,\n",
    "    '17': 4,\n",
    "    '21': 3,    \n",
    "    'rest': 1,\n",
    "}\n",
    "interval = dataset.interval\n",
    "sfreq=256"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a18416b",
   "metadata": {},
   "source": [
    "## Algorithm 1: Canonical Correlation Analysis\n",
    "\n",
    "Canonical Correlation Analysis [2] is a fast and relatively performant algorithm that finds a spatial filter to isolate the EEG activity oscillating at the frequencies of interest. It works by constructing a spatial filter of which the output maximally correlates with sinusoidal template signals at the frequencies of interest and their harmonics. The code below plots an example of the template signals for the frequencies of interest and their first harmonic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abfa880e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "base_freqs = [13,17,21]\n",
    "harmonics = [1,2,3]\n",
    "x = np.linspace(0, 2, sfreq*2)\n",
    "i = 0\n",
    "_,ax = plt.subplots(1,1,figsize=(17,6))\n",
    "y_ticks = []\n",
    "y_ticklabels = []\n",
    "for f in base_freqs:\n",
    "    for h in harmonics: \n",
    "        ax.plot(x,np.sin(f*h*np.pi*x)+i*6)\n",
    "        ax.plot(x,np.cos(f*h*np.pi*x)+i*6+2)\n",
    "        y_ticks.append(i*6)\n",
    "        y_ticks.append(i*6+2)\n",
    "        y_ticklabels.append(f'sin({f}*{h}*π)')\n",
    "        y_ticklabels.append(f'cos({f}*{h}*π)')\n",
    "        i+=1\n",
    "ax.set_yticks(y_ticks)\n",
    "ax.set_yticklabels(y_ticklabels)\n",
    "ax.set_title('CCA template signals for the 2 first harmonics')\n",
    "ax.set_xlabel('Time (s)')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36f6eecc",
   "metadata": {},
   "source": [
    "To use this algorithm, we first let MOABB construct a suiting preprocessing pipeline. The pipeline `paradigm_bandpass` will filter the data between 3Hz and 20Hz. To reduce computational load, we intend to use 2 harmonics to construct the template signals. The highest harmonic of the highest frequency 8.57Hz\\*3=25,71Hz falls in this filter band."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d78997f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from moabb.paradigms import SSVEP\n",
    "\n",
    "n_classes=3\n",
    "paradigm_cca = SSVEP(fmin=3, fmax=30, n_classes=n_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d2191fd",
   "metadata": {},
   "source": [
    "The CCA classifier is then constructed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8403cff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from moabb.pipelines import SSVEP_CCA\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.cross_decomposition import CCA\n",
    "\n",
    "pipelines_cca = dict()\n",
    "pipelines_cca[\"CCA\"] = make_pipeline(\n",
    "    SSVEP_CCA(\n",
    "        interval=interval,\n",
    "        freqs=paradigm_cca.used_events(dataset),\n",
    "        n_harmonics=3\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd9273e4",
   "metadata": {},
   "source": [
    "## Algorithm 2: Riemannian Geometry\n",
    "\n",
    "Riemannian Geometry [3] is a relatively new and very performant method in biosignal classification. \n",
    "In Riemannian Geometry classifiers, epochs are represented as covariance matrices. They contain a lot of information about the signal, and because they have some nice mathematical properties, they can be classified using optimalization on the Riemannian manifold. While the covariance matrices are highly dimensional, the assumption that they lie on a specific manifold greatly reduces the search space for an optimal solution.\n",
    "\n",
    "The covariance matrix of a multichannel signal epoch of shape `(n_channels, n_times)` has shape `(n_channels, n_channels)`. Because SSVEP requires us to also include frequency information, we need some specific preprocessing which is taken care of by the `FilterBankSSVEP` processing paradigm.\n",
    "To obtain SSVEP feature covariance matrices, `FilterBankSSVEP` applies a time-frequency transformation like in the previous notebook to the signal by applying multiple band-pass filters at the frequencies of interest and their harmonics. This results in signal epochs of shape `(n_channels, n_times, n_freqs*n_harmonics)`. MOABB provides an  `ExtendedSSVEPSignal` transformer, which flattens the epochs into shape `(n_chanels*n_freqs*n_harmonics, n_times)`. Finally, covariances of shape `(n_chanels*n_freqs*n_harmonics, n_chanels*n_freqs*n_harmonics)` can then be extracted and classified on the Riemannian manifold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d93fe9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from moabb.paradigms import FilterBankSSVEP\n",
    "\n",
    "filter_freqs = np.outer([13,17,21],[1,2,3]).flatten()\n",
    "print(filter_freqs)\n",
    "filters = [[f-.1, f+.1] for f in filter_freqs]\n",
    "\n",
    "paradigm_rg = FilterBankSSVEP(n_classes=n_classes, filters=filters)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bd696d2",
   "metadata": {},
   "source": [
    "The code below plots the mean extracted covariance for each stimulation frequency. They show clear `(n_channels, n_channels)`-sized blocks around each target frequency and their harmonics. Note how MOABB's `FilterBankSSVEP`does not apply baseline correction in the time frequeny domain, causing the harmonics to have very weak covariance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a035bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from moabb.pipelines import ExtendedSSVEPSignal\n",
    "from pyriemann.estimation import Covariances\n",
    "from mne import concatenate_raws\n",
    "\n",
    "subj,session = 3, 'session_0'\n",
    "raw = concatenate_raws(list(dataset.get_data(subjects=[subj])[subj][session].values()))\n",
    "X_tfr,labels,_ = paradigm_rg.process_raw(raw, dataset)\n",
    "X_tfr_flat = ExtendedSSVEPSignal().fit_transform(X_tfr, labels)\n",
    "scm = Covariances(estimator='scm')\n",
    "\n",
    "fig, axs=plt.subplots(1,len(base_freqs), figsize=(17,6),sharex=True,sharey=True)\n",
    "for i,l in enumerate(base_freqs):\n",
    "    cov = np.mean(scm.fit_transform(X_tfr_flat[labels==str(l)]), axis=0)\n",
    "    axs[i].imshow(cov,cmap=plt.get_cmap('RdBu_r'))\n",
    "    axs[i].set_title(f'{l}Hz')\n",
    "    axs[i].grid(False)\n",
    "    ticks=np.arange(X_tfr.shape[3])*X_tfr.shape[1]+X_tfr.shape[1]/2\n",
    "    axs[i].set_xticks(ticks)\n",
    "    axs[i].set_yticks(ticks)\n",
    "    axs[i].set_yticklabels(filter_freqs)\n",
    "    axs[i].set_yticklabels(filter_freqs)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faa5bdee",
   "metadata": {},
   "source": [
    "Finally, we use `pyRiemann` to construct a classification pipeline that uses Riemannian Geometry to project these covariance matrices to a lower dimensional space (the tangent space). In this low dimensional space, a simple classifier like logistic regression can discriminate the classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8ecdadb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyriemann.tangentspace import TangentSpace\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "pipelines_rg = dict()\n",
    "pipelines_rg[\"RG+logreg\"] = make_pipeline(\n",
    "    ExtendedSSVEPSignal(),\n",
    "    Covariances(estimator=\"lwf\"),\n",
    "    TangentSpace(),\n",
    "    LogisticRegression(solver=\"lbfgs\", multi_class=\"auto\"),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a121467",
   "metadata": {},
   "source": [
    "## Algorithm 3: Frequency band power"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e851383d",
   "metadata": {},
   "source": [
    "In this part, you will reimplement the frequency band power feature extraction method with baselining. Choose a fitting preprocessing paradigm(bandpass `SSVEP`, or `FilterBankSSVEP`) and implement a scikit-learn pipeline that applies baseline correction to each frequency band of each channel of each epoch. As a final step in the pipeline, apply a suiting classifier to classify the extracted features.\n",
    "\n",
    "**Hint**: You can implement [scikit-learn transformers](https://scikit-learn.org/stable/developers/develop.html)  with the following template:\n",
    "```\n",
    "class MyTransformer(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def __init__(self, **params):\n",
    "        ...\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        ...\n",
    "        return self\n",
    "        \n",
    "    def transform(self, X, y=None):\n",
    "        ...\n",
    "```\n",
    "\n",
    "or by plugging your own function into a [FunctionTransformer](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.FunctionTransformer.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd7455ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "\n",
    "paradigm_bandpower = # TODO\n",
    "\n",
    "pipelines_bandpower = dict()\n",
    "pipelines_bandpower['power+logreg'] = make_pipeline(\n",
    "    # TODO\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e687eb52",
   "metadata": {},
   "source": [
    "## Evaluate algorithm performance\n",
    "\n",
    "You can run the following snippets to evaluate and compare the performance of your algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7970262",
   "metadata": {},
   "outputs": [],
   "source": [
    "from moabb.evaluations import WithinSessionEvaluation\n",
    "\n",
    "evaluation_cca = WithinSessionEvaluation(\n",
    "    paradigm=paradigm_cca,\n",
    "    datasets=dataset,\n",
    "    suffix=\"ssvep_workshop_cca\",\n",
    "    overwrite=False\n",
    ")\n",
    "results_cca = evaluation_cca.process(pipelines_cca)\n",
    "results_cca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "302ed204",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_rg = WithinSessionEvaluation(\n",
    "    paradigm=paradigm_rg,\n",
    "    datasets=dataset,\n",
    "    suffix=\"ssvep_workshop_rg\",\n",
    "    overwrite=False\n",
    ")\n",
    "results_rg = evaluation_rg.process(pipelines_rg)\n",
    "results_rg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53f412a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_bandpower = WithinSessionEvaluation(\n",
    "    paradigm=paradigm_bandpower,\n",
    "    datasets=dataset,\n",
    "    suffix=\"ssvep_workshop_bandpower\",\n",
    "    overwrite=True\n",
    ")\n",
    "results_bandpower = evaluation_bandpower.process(pipelines_bandpower)\n",
    "results_bandpower"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "187447dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "results = pd.concat([results_cca, results_rg, results_bandpower])\n",
    "ax = sns.stripplot(data=results, y=\"score\", x=\"pipeline\", zorder=1, alpha=.5, palette=\"Set1\")\n",
    "ax = sns.pointplot(data=results, y=\"score\", x=\"pipeline\" , palette=\"Set1\")\n",
    "ax.set_ylabel(\"Accuracy\")\n",
    "ax.axhline(1/n_classes)\n",
    "_ = ax.set_ylim(0,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1b20910",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "[2] Bin, G., Gao, X., Yan, Z., Hong, B., & Gao, S. (2009). An online multi-channel SSVEP-based brain-computer interface using a canonical correlation analysis method. Journal of neural engineering, 6(4), 046002. https://doi.org/10.1088/1741-2560/6/4/046002\n",
    "\n",
    "[3] Kalunga, E. K., Chevallier, S., Barthélemy, Q., Djouani, K., Monacelli, E., & Hamam, Y. (2016). Online SSVEP-based BCI using Riemannian geometry. Neurocomputing, 191, 55-68. https://doi.org/10.1016/j.neucom.2016.01.007"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
