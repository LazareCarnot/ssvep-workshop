{"cells":[{"cell_type":"markdown","source":["## Install packages"],"metadata":{"id":"q3jUc5v15FIq"},"id":"q3jUc5v15FIq"},{"cell_type":"code","source":["!pip install \"numpy<1.20\"\n","!pip install \"pyyaml<=5.3.1\"\n","!pip install \"scikit-learn<1.3\"\n","!pip install mne\n","!pip install moabb\n","!pip install jupyter\n","!pip install seaborn"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nGtTQjUyCLHr","outputId":"55e7dcd8-0a15-48ce-d9e3-087f3a802c01"},"id":"nGtTQjUyCLHr","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting numpy<1.20\n","  Downloading numpy-1.19.5.zip (7.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.3/7.3 MB\u001b[0m \u001b[31m41.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","Building wheels for collected packages: numpy\n"]}]},{"cell_type":"code","source":["# !pip install mne\n","# !pip install MOABB\n","# !pip install pyriemann\n","# !pip install seaborn"],"metadata":{"id":"wzH3hE7V5EC8"},"id":"wzH3hE7V5EC8","execution_count":null,"outputs":[]},{"cell_type":"markdown","id":"137f06fd","metadata":{"id":"137f06fd"},"source":["# Verifiyng your installation\n","\n","## Verify python environment\n","\n","If your python environment is set up correctly, the following imports should succeed."]},{"cell_type":"code","execution_count":null,"id":"03066a28","metadata":{"id":"03066a28"},"outputs":[],"source":["import mne\n","import moabb\n","import pyriemann\n","import seaborn"]},{"cell_type":"markdown","id":"a0ea7864","metadata":{"id":"a0ea7864"},"source":["## Verify MOABB Installation\n","\n","Now let's check if MOABB is configured correctly."]},{"cell_type":"code","execution_count":null,"id":"ffd68399","metadata":{"id":"ffd68399"},"outputs":[],"source":["import os\n","import os.path as osp\n","from mne import get_config\n","from moabb.utils import set_download_dir"]},{"cell_type":"markdown","id":"a937903f","metadata":{"id":"a937903f"},"source":["## Setting the download directory (optional)\n","\n","Using MOABB, it is very easy to download and to extract EEG data from open datasets. Let's first select where we want to download the datasets. You can safely skip this part if you have no specific storage space requirements on your computer.\n","\n","You can choose to change the download directory to any path of your choice. If the path/folder doesn’t exist, it will be created for you."]},{"cell_type":"code","execution_count":null,"id":"7c54a693","metadata":{"id":"7c54a693"},"outputs":[],"source":["original_path = get_config(\"MNE_DATA\")\n","print(f\"The download directory is currently {original_path}\")\n","new_path = osp.join(osp.expanduser(\"~\"), \"mne_data\") # change this to your desired path\n","# new_path = \"/content/sample_data\"\n","set_download_dir(new_path)"]},{"cell_type":"code","execution_count":null,"id":"38dac71d","metadata":{"id":"38dac71d"},"outputs":[],"source":["check_path = get_config(\"MNE_DATA\")\n","print(f\"Now the download directory has been changed to {check_path}\")"]},{"cell_type":"markdown","id":"012ffa07","metadata":{"id":"012ffa07"},"source":["## Downloading or copying datasets\n","\n","n case the internet connection is slow during the workshop, we have already prepared the datasets: several USB key are available and you could copy/paste the files directly on your computer.\n","\n","Your should copy the datasets inside the mne_data that is in your home directory or in the folder you specified above. If you are not sure, please ask!\n","\n","You should see at least the `MNE-ssvepexo-data` folder as listed below when you execute the following code:"]},{"cell_type":"code","execution_count":null,"id":"ef740b42","metadata":{"id":"ef740b42"},"outputs":[],"source":["dataset_path = get_config(\"MNE_DATA\")\n","print(f\"The folder {check_path} contains:\")\n","os.listdir(dataset_path)"]},{"cell_type":"markdown","id":"2d48f2a6","metadata":{"id":"2d48f2a6"},"source":["Otherwise, you can download the dataset by executing the following:"]},{"cell_type":"code","execution_count":null,"id":"8f868f2b","metadata":{"id":"8f868f2b"},"outputs":[],"source":["from moabb.datasets import SSVEPExo\n","\n","datasets = [\n","    SSVEPExo(),\n","]\n","for dataset in datasets:\n","    dataset.download()\n","dataset_path = get_config(\"MNE_DATA\")\n","print(f\"The folder {check_path} contains:\")\n","os.listdir(dataset_path)"]},{"cell_type":"markdown","metadata":{"id":"427d66f4"},"source":["# Discovering MNE and MOABB\n","\n","## MNE\n","> \\[MNE is an\\] Open-source Python package for exploring, visualizing, and analyzing human neurophysiological data: MEG, EEG, sEEG, ECoG, NIRS, and more.\n","\n","More information and documentation can be found at https://mne.tools/stable/index.html\n","\n","\n","### Downloading a dataset\n","\n","To discover the features of MNE, we will make use of MOABB to download an SSVEP BCI dataset. MOABB internally uses MNE for data representation, so the downloaded data will be returned in an MNE format.\n","\n","The dataset used here is the `SSVEPExo` dataset from the University of Versailles [1].\n","\n","> The datasets contains recording from 12 male and female subjects aged between 20 and 28 years. Informed consent was obtained from all subjects, each one has signed a form attesting her or his consent. The subject sits in an electric wheelchair, his right upper limb is resting on the exoskeleton. The exoskeleton is functional but is not used during the recording of this experiment.\n","\\\n","A panel of size 20x30 cm is attached on the left side of the chair, with 3 groups of 4 LEDs blinking at different frequencies. Even if the panel is on the left side, the user could see it without moving its head. The subjects were asked to sit comfortably in the wheelchair and to follow the auditory instructions, they could move and blink freely.\n","\\\n","A sequence of trials is proposed to the user. A trial begin by an audio cue indicating which LED to focus on, or to focus on a fixation point set at an equal distance from all LEDs for the reject class. A trial lasts 5 seconds and there is a 3 second pause between each trial. The evaluation is conducted during a session consisting of 32 trials, with 8 trials for each frequency (13Hz, 17Hz and 21Hz) and 8 trials for the reject class, i.e. when the subject is not focusing on any specific blinking LED.\n","\\\n","There is between 2 and 5 sessions for each user, recorded on different days, by the same operators, on the same hardware and in the same conditions.\n","\n","https://neurotechx.github.io/moabb/generated/moabb.datasets.SSVEPExo.html#moabb.datasets.SSVEPExo"],"id":"427d66f4"},{"cell_type":"code","execution_count":null,"metadata":{"id":"408582ec"},"outputs":[],"source":["from moabb.datasets import SSVEPExo\n","\n","dataset = SSVEPExo()\n","dataset.download()\n","dataset.get_data()"],"id":"408582ec"},{"cell_type":"markdown","metadata":{"id":"00a07399"},"source":["Let's create a variable `raw` containing the raw, unprocessed data from the first subject in this experiment. MNE gives a nice overview of the metadata of this EEG recording."],"id":"00a07399"},{"cell_type":"code","execution_count":null,"metadata":{"scrolled":true,"id":"60ea325e"},"outputs":[],"source":["subj,session,run = 1, 'session_0', 'run_0'\n","raw = dataset.get_data(subjects=[subj])[subj][session][run]\n","raw"],"id":"60ea325e"},{"cell_type":"markdown","metadata":{"id":"e35366df"},"source":["### Inspect raw data\n","\n","MNE offers a lot of useful tools for data manipulation and visualization. You can plot the locations of the elctrodes used to record the data:"],"id":"e35366df"},{"cell_type":"code","execution_count":null,"metadata":{"scrolled":true,"id":"ce69a53c"},"outputs":[],"source":["sphere=(0,-25,0,100)\n","_ = raw.plot_sensors(show_names=True, kind='topomap', sphere=sphere)"],"id":"ce69a53c"},{"cell_type":"markdown","metadata":{"id":"34fedaa8"},"source":["Plot the raw EEG data:"],"id":"34fedaa8"},{"cell_type":"code","execution_count":null,"metadata":{"scrolled":true,"id":"65afe519"},"outputs":[],"source":["_ = raw.plot(duration=4, color={'eeg':'darkblue'}, scalings=dict(eeg=1e-2))"],"id":"65afe519"},{"cell_type":"markdown","metadata":{"id":"f98fb7c4"},"source":["Or plot the power spectral density (psd). The psd applies a Fourier transform and visualizes the frequency content of the EEG signal. Notice the large peak at 50Hz (and its harmonic at 100=50\\*2Hz) caused by noise from the power grid alternating at 50Hz, and the increase in activity from 8-12Hz indicating alpha activity in the EEG. Generally, the psd has a *1/f* characteristic, meaning that lower frequencies will have relatively higher power regardless of specific relevant brain activity occurring at these frequencies. Because no preprocessing was applied here, the SSVEP stimulation frequencies are not yet clearly visible from the psd."],"id":"f98fb7c4"},{"cell_type":"code","execution_count":null,"metadata":{"scrolled":true,"id":"28414ed9"},"outputs":[],"source":["_ = raw.plot_psd(sphere=sphere)"],"id":"28414ed9"},{"cell_type":"markdown","metadata":{"id":"898b2224"},"source":["Finally, to make preprocessing and classification easier, MNE can extract events that are recorded in a stimulation channel in the EEG. For SSVEP, these events signify the onsets of the stimulations of different targets. Events can also be used as classes for classifying the three SSVEP different frequencies."],"id":"898b2224"},{"cell_type":"code","execution_count":null,"metadata":{"id":"47562be2"},"outputs":[],"source":["import numpy as np\n","from mne import pick_types\n","\n","stim_idc = pick_types(raw.info, eeg=False, stim=True)\n","[raw.ch_names[i] for i in stim_idc]"],"id":"47562be2"},{"cell_type":"code","execution_count":null,"metadata":{"id":"c7b51e6c"},"outputs":[],"source":["from mne import find_events\n","from mne.viz import plot_events\n","\n","events = find_events(raw)\n","events"],"id":"c7b51e6c"},{"cell_type":"code","execution_count":null,"metadata":{"id":"39bf4eb7"},"outputs":[],"source":["_= plot_events(events)"],"id":"39bf4eb7"},{"cell_type":"markdown","metadata":{"id":"f22f710a"},"source":["## MOABB\n","\n","The Mother Of All BCI Benchmarks is a package for interfacing with various EEG-BCI datasets from multiple paradigms and defines a framework to benchmark algorithms.\n","\n","More information and documentation can be found at https://neurotechx.github.io/moabb/\n","\n","### Paradigm\n","\n","MOABB can implement standardized preprocessing pipelines that can be applied to multiple datasets to fairly compare these in a benchmark. MOABB calls a preprocessing pipeline a paradigm."],"id":"f22f710a"},{"cell_type":"code","execution_count":null,"metadata":{"id":"f5f86ae2"},"outputs":[],"source":["from moabb.paradigms import SSVEP\n","dataset.event_id= {\n","    '13': 2,\n","    '17': 4,\n","    '21': 3,\n","    'rest': 1,\n","}\n","paradigm = SSVEP(fmin=10, fmax=25, n_classes=3)"],"id":"f5f86ae2"},{"cell_type":"markdown","metadata":{"id":"c07d6c43"},"source":["### Pipelines\n","\n","Classification algorithms can equally be defined independent of the dataset and are implemented using [Scikit-Learn pipelines](https://scikit-learn.org/stable/modules/compose.html#pipeline) to allow for multiple feature extraction, transformation and classification steps."],"id":"c07d6c43"},{"cell_type":"code","execution_count":null,"metadata":{"id":"319f910b"},"outputs":[],"source":["from sklearn.pipeline import make_pipeline\n","from moabb.pipelines import SSVEP_CCA\n","\n","\n","interval = dataset.interval\n","freqs = paradigm.used_events(dataset)\n","\n","pipelines = dict()\n","pipelines[\"CCA\"] = make_pipeline(\n","    SSVEP_CCA(interval=interval, freqs=freqs, n_harmonics=3)\n",")"],"id":"319f910b"},{"cell_type":"markdown","metadata":{"id":"4340104d"},"source":["### Evaluation\n","\n","Finally, when we have defined a paradigm and some pipelines, we can run the benchmark and evaluate BCI algorithm performance."],"id":"4340104d"},{"cell_type":"code","execution_count":null,"metadata":{"id":"af957e5d"},"outputs":[],"source":["from moabb.evaluations import WithinSessionEvaluation\n","\n","\n","evaluation = WithinSessionEvaluation(\n","    paradigm=paradigm,\n","    datasets=dataset,\n","    suffix='ssvep_workshop_moabb_intro',\n","    overwrite=True\n",")\n","results = evaluation.process(pipelines)\n","results"],"id":"af957e5d"},{"cell_type":"code","execution_count":null,"metadata":{"id":"139d09e7"},"outputs":[],"source":["import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","plt.figure()\n","sns.catplot(kind='bar', x=\"score\", y=\"subject\", hue=None, data=results)"],"id":"139d09e7"},{"cell_type":"markdown","metadata":{"id":"dcc16faf"},"source":["## References\n","\n","[1] Emmanuel K. Kalunga, Sylvain Chevallier, Quentin Barthelemy. “Online SSVEP-based BCI using Riemannian Geometry”. Neurocomputing, 2016. arXiv report: https://arxiv.org/abs/1501.03227"],"id":"dcc16faf"},{"cell_type":"markdown","metadata":{"id":"859362ec"},"source":["# SSVEP Preprocessing (solution)\n","\n","In the following notebook, you will implement some steps to clean up the recorded EEG data in order to extract interpretable frequency content for the different SSVEP classes. When in doubt, refer to the MNE documentation at https://mne.tools/stable/python_reference.html, or don't hesitate to ask a question or help each other out.\n","\n","## Download the SSVEP Exoskeleton dataset\n","\n","First, we again load the `SSVEPExo` dataset and extract the raw, unprocessed data into variable `raw`of datatype `mne.io.Raw`."],"id":"859362ec"},{"cell_type":"code","execution_count":null,"metadata":{"id":"369802c3"},"outputs":[],"source":["from moabb.datasets import SSVEPExo\n","\n","dataset = SSVEPExo()\n","dataset.download()\n","dataset.get_data()\n","subj,session,run = 3, 'session_0', 'run_0'\n","raw = dataset.get_data(subjects=[subj])[subj][session][run]\n","sphere=(0,-25,0,100)\n","raw"],"id":"369802c3"},{"cell_type":"markdown","metadata":{"id":"3e32d4c1"},"source":["Without any preprocessing, we can already see distinct peaks at the frequencies of interest for this SSVEP paradigm (13Hz, 17Hz and 21Hz) in the power spectral density. However, this will not always be the case, and these peaks are overshadowed by the power of low frequencies and other peaks the alpha activity or the powerline noise."],"id":"3e32d4c1"},{"cell_type":"markdown","metadata":{"id":"f83d3b86"},"source":["## Rereference\n","\n","Usually, the first step in EEG preprocessing is rereferencing. EEG data is recorded as differences in electrical potential between each electrode and a fixed reference electrode, which is not present in the recorded data. Afterwards, this reference can be changed in data processing to highlight some differences in the data and remove noise that is present in all electrodes.\n","\n","**Output**: the `raw : mne.io.Raw` variable rereferenced using an apt method.\n","\n","**Hint:** https://mne.tools/stable/generated/mne.io.Raw.html?highlight=set_eeg_reference#mne.io.Raw.set_eeg_reference"],"id":"f83d3b86"},{"cell_type":"code","execution_count":null,"metadata":{"id":"45491faa"},"outputs":[],"source":["import matplotlib.pyplot as plt\n","\n","target_frequencies = [0,13,21,17]\n","fig, ax = plt.subplots(1,1,figsize=(17,6))\n","fig = raw.plot_psd(sphere=sphere,fmax=64,ax=ax, show=False)\n","for f in target_frequencies:\n","    ax.axvline(f, color='red', alpha=0.3)\n","fig.show()"],"id":"45491faa"},{"cell_type":"code","execution_count":null,"metadata":{"id":"5b33e045"},"outputs":[],"source":["# Since no far-away electrodes that contain other brain activity\n","# but not the activity of interest are present, rereferencing can be ommitted here.\n","#_ = raw.set_eeg_reference('average')"],"id":"5b33e045"},{"cell_type":"code","execution_count":null,"metadata":{"scrolled":true,"id":"5d4f9aae"},"outputs":[],"source":["fig, ax = plt.subplots(1,1,figsize=(17,6))\n","fig = raw.plot_psd(sphere=sphere,fmax=64,ax=ax, show=False)\n","for f in target_frequencies:\n","    ax.axvline(f, color='red', alpha=0.3)\n","fig.show()"],"id":"5d4f9aae"},{"cell_type":"markdown","metadata":{"id":"e4270f61"},"source":["## Filter\n","\n","Next let's remove the powerline noise.\n","\n","**Output**: the `raw : mne.io.Raw` variable filtered to drop the European powerline frequency and its harmonics.\n","\n","**Hint**: https://mne.tools/stable/generated/mne.io.BaseRaw.html#mne.io.BaseRaw.notch_filternotch_filter#mne.io.BaseRaw.notch_filter"],"id":"e4270f61"},{"cell_type":"code","execution_count":null,"metadata":{"id":"5ac19739"},"outputs":[],"source":["powerline_freq = 50\n","# The data sample rate is 256Hz, hence the highest possible (Nyquist)\n","# frequency is 256Hz/2=128Hz.\n","# The maximum powerline harmonic we can use is thus 50Hz*2=100Hz < 128Hz\n","_ = raw.notch_filter([powerline_freq,powerline_freq*2])"],"id":"5ac19739"},{"cell_type":"code","execution_count":null,"metadata":{"id":"c141f91e"},"outputs":[],"source":["fig, ax = plt.subplots(1,1,figsize=(17,6))\n","fig = raw.plot_psd(sphere=sphere,fmax=64,ax=ax, show=False)\n","for f in target_frequencies:\n","    ax.axvline(f, color='red', alpha=0.3)\n","fig.show()"],"id":"c141f91e"},{"cell_type":"markdown","metadata":{"id":"8b692b4f"},"source":["## Cut epochs\n","\n","The EEG is recorded as a continuous, multi-channel time series and is represented as such by the `mne.io.Raw` datatype. We are, however, only interested in the EEG activity during SSVEP stimulation, which might only occur sporadically troughout the recording. In order to drop irrelevant timepoints and end up with labeled segments of EEG data suited for analysis and classification, cut the continous signal into time segments (epochs) based on the events present in the stimulation channel."],"id":"8b692b4f"},{"cell_type":"code","execution_count":null,"metadata":{"id":"ede1c7ec"},"outputs":[],"source":["event_id = {\n","    'rest': 1,\n","    'stimulation/13Hz': 2,\n","    'stimulation/21Hz': 3,\n","    'stimulation/17Hz': 4,\n","}"],"id":"ede1c7ec"},{"cell_type":"markdown","metadata":{"id":"081e3f37"},"source":["Cut the continuous EEG signal in epochs each lasting for the entire duration of one SSVEP stimulation and including some pre-stimulation activity for baseline correction (see later).\n","\n","**Output**: a variable `epochs : mne.Epochs` containing one epochs per event.\n","\n","**Hint**: https://mne.tools/stable/generated/mne.Epochs.html"],"id":"081e3f37"},{"cell_type":"code","execution_count":null,"metadata":{"id":"3fd1dab2"},"outputs":[],"source":["from mne import find_events, Epochs\n","\n","events = find_events(raw)\n","epochs = Epochs(raw, events=events, event_id=event_id, tmin=-3, tmax=5, baseline=(None,0), preload=True)"],"id":"3fd1dab2"},{"cell_type":"markdown","metadata":{"id":"2caa1c02"},"source":["The psd should look a lot cleaner now and can be split up per stimulation class. Some harmonics should also be visible now, check if you can spot them."],"id":"2caa1c02"},{"cell_type":"code","execution_count":null,"metadata":{"id":"f62806bd"},"outputs":[],"source":["fig, axs = plt.subplots(1,4, figsize=(17,6), sharex=True, sharey=True)\n","for i,label in enumerate(event_id.keys()):\n","    axs[i].axvline(target_frequencies[i], color='red', alpha=0.3)\n","    epochs[label].plot_psd(\n","        sphere=sphere, tmin=0, fmax=64, show=False, ax=axs[i],\n","    )\n","    axs[i].set_title(label)\n","fig.show()"],"id":"f62806bd"},{"cell_type":"markdown","metadata":{"id":"b05bc92d"},"source":["This looks nice, but the result is not really fit for analysis. For instance, the alpha activity and the lowest frequencies are still a lot more powerful than the frequencies of interest."],"id":"b05bc92d"},{"cell_type":"markdown","metadata":{"id":"63c0d753"},"source":["## Frequency band power feature extraction\n","\n","### Time-frequency transform\n","\n","To inspect which frequencies are prevalent in which classes and to allow for feature extraction, we can now plot frequency powers for the stimulation frequencies and their harmonics. We do this by applying a set of multitaper filters for the frequencies of interest to the data. If you want to gain a better understanding of EEG analysis in the time-frequency domain, please refer to Mike X Cohen's Analyzing Neural Time Series Data videos: https://www.youtube.com/channel/UCUR_LsXk7IYyueSnXcNextQ/playlists?view=50&sort=dd&shelf_id=1"],"id":"63c0d753"},{"cell_type":"code","execution_count":null,"metadata":{"id":"97dfdb5f"},"outputs":[],"source":["import numpy as np\n","from mne.time_frequency import tfr_multitaper, tfr_morlet\n","\n","base_freqs = np.array([13]*9 + [17]*7 + [21]*6)\n","harmonics = np.array([1,2,3,4,5,6,7,8,9,1,2,3,4,5,6,7,1,2,3,4,5,6])\n","freqs = base_freqs*harmonics\n","n_cycles = freqs*3\n","epochs_tfr = tfr_morlet(epochs, freqs=freqs, n_cycles=n_cycles, average=False, return_itc=False)\n","epochs_tfr"],"id":"97dfdb5f"},{"cell_type":"code","execution_count":null,"metadata":{"id":"b5298172"},"outputs":[],"source":["import seaborn as sns\n","import pandas as pd\n","from mne.epochs import make_metadata\n","\n","mean_chan_power = epochs_tfr.data.mean(axis=(1,3))\n","sfreq = epochs.info['sfreq']\n","meta,_,_ = make_metadata(events, event_id, epochs.tmin, epochs.tmax, sfreq)\n","labels = meta['event_name']\n","df = pd.DataFrame(mean_chan_power.T, columns=labels)\n","df['Base frequency (Hz)'] = base_freqs\n","df['Harmonic'] = harmonics\n","df = df.melt(id_vars=['Base frequency (Hz)', 'Harmonic'], var_name='Label', value_name='Power (µV²)')\n","sns.catplot(kind='bar', col='Label', data=df, x='Base frequency (Hz)', hue='Harmonic', y='Power (µV²)', ax=axs[i], palette='magma')"],"id":"b5298172"},{"cell_type":"markdown","metadata":{"id":"715e8919"},"source":["### Baseline correction\n","\n","Unfortunately, these features are not that easy to interpret and unfit to use for classification.\n","Ideally, the stimulation frequency of a class would be present as the frequency with the highest power.\n","There are several problems preventing this:\n","* The 1/f scaling characteristic makes it hard to visualize data across a wide frequency range. In the example above, the harmonics, while containing relevant information, fade away as they have increasingly higher frequencies.\n","* The 1/f scaling characteristic also prevents quantitative comparisons across frequencies. In the example above, the 1st harmonic of 13Hz has higher power than the first harmonic of 21Hz while 21Hz is being stimulated.\n","* Background noise at specific frequencies contaminates specific epochs and/or channels.\n","* Task-related changes in power in specific epochs and/or channels can be obscured by background activity or noise of higher power that is present regardless of the stimulation (e.g. alpha activity).\n","* It is hard to discern the trials where no targets were selected from the others.\n","\n","To reveal the increase in frequency power generated by SSVEP stimulation, instead of using the raw power at specific frequencies as features, in each epoch, channel and frequency we want to look at increases or decreases of power relative to some baseline period in which no stimulation is happening. This will correct for the 1/f characteristic, and continuous noise present in some epochs or channels.\n","\n","Choose a relevant baselining window and method and apply baselining to the timfe-frequency epochs. Does this work well for all subjects?\n","\n","**Output**: the baseline corrected `epochs_tfr: mne.time_frequency.EpochsTFR` variable\n","\n","**Hint**: https://mne.tools/stable/generated/mne.time_frequency.EpochsTFR.html#mne.time_frequency.EpochsTFR.apply_baseline"],"id":"715e8919"},{"cell_type":"code","execution_count":null,"metadata":{"id":"cd7637d0"},"outputs":[],"source":["epochs_tfr.apply_baseline((-2.5, -.5), mode='ratio')"],"id":"cd7637d0"},{"cell_type":"markdown","metadata":{"id":"b515e597"},"source":["Finally, after baseline correction, discard the baseline period so the resulting epochs contain only stimulated data.\n","\n","**Output**: the cropped `epochs_tfr: mne.time_frequency.EpochsTFR` variable starting at 0s.\n","\n","**Hint**: https://mne.tools/stable/generated/mne.time_frequency.EpochsTFR.html#mne.time_frequency.EpochsTFR.crop"],"id":"b515e597"},{"cell_type":"code","execution_count":null,"metadata":{"id":"ec644bdd"},"outputs":[],"source":["epochs.crop(tmin=0, tmax=5)"],"id":"ec644bdd"},{"cell_type":"code","execution_count":null,"metadata":{"id":"f740e44a"},"outputs":[],"source":["mean_chan_power = epochs_tfr.data.mean(axis=(1,3))\n","mean_chan_power_db = 10*np.log10(mean_chan_power)\n","\n","df = pd.DataFrame(mean_chan_power.T, columns=labels)\n","df['Base frequency (Hz)'] = base_freqs\n","df['Harmonic'] = harmonics\n","df = df.melt(id_vars=['Base frequency (Hz)', 'Harmonic'], var_name='Label', value_name='Power (dB)')\n","sns.catplot(kind='bar', col='Label', data=df, x='Base frequency (Hz)', hue='Harmonic', y='Power (dB)', ax=axs[i], palette='magma')"],"id":"f740e44a"},{"cell_type":"markdown","metadata":{"id":"f3db6f3b"},"source":["# SSVEP decoding algorithms\n","\n","In this notebook, we'll take a look at some algorithms for decoding SSVEP responsens.\n","We'll make use of the `SSVEPExo` dataset and some existing state-of-the-art SSVEP decoding algorithms.\n","the dataset and the algorithms are accessed trough MOABB. You will also implement your own decoding algorithm, based on the feature extraction pipeline implemented in the previous notebook.\n","\n","To be able to compare all algorithms, we'll only investigate the trials where stimulation is happening and do not attempt to classify the `rest` state."],"id":"f3db6f3b"},{"cell_type":"code","execution_count":null,"metadata":{"id":"5cc2877c"},"outputs":[],"source":["from moabb.datasets import SSVEPExo\n","\n","dataset = SSVEPExo()\n","dataset.event_id= {\n","    '13': 2,\n","    '17': 4,\n","    '21': 3,\n","    'rest': 1,\n","}\n","interval = dataset.interval\n","sfreq=256"],"id":"5cc2877c"},{"cell_type":"markdown","metadata":{"id":"5a18416b"},"source":["## Algorithm 1: Canonical Correlation Analysis\n","\n","Canonical Correlation Analysis [2] is a fast and relatively performant algorithm that finds a spatial filter to isolate the EEG activity oscillating at the frequencies of interest. It works by constructing a spatial filter of which the output maximally correlates with sinusoidal template signals at the frequencies of interest and their harmonics. The code below plots an example of the template signals for the frequencies of interest and their first harmonic."],"id":"5a18416b"},{"cell_type":"code","execution_count":null,"metadata":{"id":"3c0338d5"},"outputs":[],"source":["import matplotlib.pyplot as plt\n","import numpy as np\n","\n","base_freqs = [13,17,21]\n","harmonics = [1,2,3]\n","#harmonics = [1]\n","\n","x = np.linspace(0, 2, sfreq*2)\n","i = 0\n","_,ax = plt.subplots(1,1,figsize=(17,6))\n","y_ticks = []\n","y_ticklabels = []\n","for f in base_freqs:\n","    for h in harmonics:\n","        ax.plot(x,np.sin(f*h*np.pi*x)+i*6)\n","        ax.plot(x,np.cos(f*h*np.pi*x)+i*6+2)\n","        y_ticks.append(i*6)\n","        y_ticks.append(i*6+2)\n","        y_ticklabels.append(f'sin({f}*{h}*π)')\n","        y_ticklabels.append(f'cos({f}*{h}*π)')\n","        i+=1\n","ax.set_yticks(y_ticks)\n","ax.set_yticklabels(y_ticklabels)\n","ax.set_title('CCA template signals for the 2 first harmonics')\n","ax.set_xlabel('Time (s)')\n"],"id":"3c0338d5"},{"cell_type":"markdown","metadata":{"id":"5c6ce670"},"source":["To use this algorithm, we first let MOABB construct a suiting preprocessing pipeline. The pipeline `paradigm_bandpass` will filter the data between 3Hz and 20Hz. To reduce computational load, we intend to use 2 harmonics to construct the template signals. The highest harmonic of the highest frequency 8.57Hz\\*3=25,71Hz falls in this filter band."],"id":"5c6ce670"},{"cell_type":"code","execution_count":null,"metadata":{"id":"d78997f9"},"outputs":[],"source":["from moabb.paradigms import SSVEP\n","\n","n_classes=3\n","paradigm_cca = SSVEP(fmin=3, fmax=30, n_classes=n_classes)"],"id":"d78997f9"},{"cell_type":"markdown","metadata":{"id":"0345ba35"},"source":["The CCA classifier is then constructed:"],"id":"0345ba35"},{"cell_type":"code","execution_count":null,"metadata":{"id":"8403cff0"},"outputs":[],"source":["from sklearn.pipeline import make_pipeline\n","from moabb.pipelines import SSVEP_CCA\n","from sklearn.base import BaseEstimator, TransformerMixin\n","from sklearn.cross_decomposition import CCA\n","\n","pipelines_cca = dict()\n","pipelines_cca[\"CCA\"] = make_pipeline(\n","    SSVEP_CCA(\n","        interval=interval,\n","        freqs=paradigm_cca.used_events(dataset),\n","        n_harmonics=3\n","    )\n",")"],"id":"8403cff0"},{"cell_type":"markdown","metadata":{"id":"dd9273e4"},"source":["## Algorithm 2: Riemannian Geometry\n","\n","Riemannian Geometry [3] is a relatively new and very performant method in biosignal classification.\n","In Riemannian Geometry classifiers, epochs are represented as covariance matrices. They contain a lot of information about the signal, and because they have some nice mathematical properties, they can be classified using optimalization on the Riemannian manifold. While the covariance matrices are highly dimensional, the assumption that they lie on a specific manifold greatly reduces the search space for an optimal solution.\n","\n","The covariance matrix of a multichannel signal epoch of shape `(n_channels, n_times)` has shape `(n_channels, n_channels)`. Because SSVEP requires us to also include frequency information, we need some specific preprocessing which is taken care of by the `FilterBankSSVEP` processing paradigm.\n","To obtain SSVEP feature covariance matrices, `FilterBankSSVEP` applies a time-frequency transformation like in the previous notebook to the signal by applying multiple band-pass filters at the frequencies of interest and their harmonics. This results in signal epochs of shape `(n_channels, n_times, n_freqs*n_harmonics)`. MOABB provides an  `ExtendedSSVEPSignal` transformer, which flattens the epochs into shape `(n_chanels*n_freqs*n_harmonics, n_times)`. Finally, covariances of shape `(n_chanels*n_freqs*n_harmonics, n_chanels*n_freqs*n_harmonics)` can then be extracted and classified on the Riemannian manifold."],"id":"dd9273e4"},{"cell_type":"code","execution_count":null,"metadata":{"id":"3b56ba70"},"outputs":[],"source":["from moabb.paradigms import FilterBankSSVEP\n","\n","filter_freqs = np.outer(base_freqs,harmonics).flatten()\n","print(filter_freqs)\n","filters = [[f-.1, f+.1] for f in filter_freqs]\n","\n","paradigm_rg = FilterBankSSVEP(n_classes=n_classes, filters=filters)"],"id":"3b56ba70"},{"cell_type":"markdown","metadata":{"id":"463fbb9e"},"source":["The code below plots the mean extracted covariance for each stimulation frequency. They show clear `(n_channels, n_channels)`-sized blocks around each target frequency and their harmonics. Note how MOABB's `FilterBankSSVEP`does not apply baseline correction in the time frequeny domain, causing the harmonics to have very weak covariance."],"id":"463fbb9e"},{"cell_type":"code","execution_count":null,"metadata":{"id":"f23af4ff"},"outputs":[],"source":["from moabb.pipelines import ExtendedSSVEPSignal\n","from pyriemann.estimation import Covariances\n","from mne import concatenate_raws\n","\n","subj,session = 3, 'session_0'\n","raw = concatenate_raws(list(dataset.get_data(subjects=[subj])[subj][session].values()))\n","X_tfr,labels,_ = paradigm_rg.process_raw(raw, dataset)\n","X_tfr_flat = ExtendedSSVEPSignal().fit_transform(X_tfr, labels)\n","scm = Covariances(estimator='scm')\n","\n","fig, axs=plt.subplots(1,len(base_freqs), figsize=(17,6),sharex=True,sharey=True)\n","covs=np.zeros((len(base_freqs), X_tfr_flat.shape[1], X_tfr_flat.shape[1]))\n","for i,l in enumerate(base_freqs):\n","    covs[i] = np.mean(scm.fit_transform(X_tfr_flat[labels==str(l)]), axis=0)\n","vmax = np.max(np.abs(covs))\n","for i,l in enumerate(base_freqs):\n","    axs[i].imshow(covs[i],cmap=plt.get_cmap('RdBu_r'),vmin=-vmax, vmax=vmax)\n","    axs[i].set_title(f'{l}Hz')\n","    axs[i].grid(False)\n","    #ticks=np.arange(X_tfr.shape[3])*X_tfr.shape[1]+X_tfr.shape[1]/2\n","    #axs[i].set_xticks(ticks)\n","    #axs[i].set_yticks(ticks)\n","    #ticklabels=['13Hz', '13*2Hz', '13*3Hz','17Hz', '17*2Hz', '17*3Hz','21Hz', '21*2Hz', '21*3Hz' ]\n","    #axs[i].set_xticklabels(ticklabels)\n","    #axs[i].set_yticklabels(ticklabels)\n","fig.show()"],"id":"f23af4ff"},{"cell_type":"markdown","metadata":{"id":"214726e1"},"source":["Finally, we use `pyRiemann` to construct a classification pipeline that uses Riemannian Geometry to project these covariance matrices to a lower dimensional space (the tangent space). In this low dimensional space, a simple classifier like logistic regression can discriminate the classes."],"id":"214726e1"},{"cell_type":"code","execution_count":null,"metadata":{"id":"f8ecdadb"},"outputs":[],"source":["from pyriemann.tangentspace import TangentSpace\n","from sklearn.linear_model import LogisticRegression\n","\n","pipelines_rg = dict()\n","pipelines_rg[\"RG+logreg\"] = make_pipeline(\n","    ExtendedSSVEPSignal(),\n","    Covariances(estimator=\"lwf\"),\n","    TangentSpace(),\n","    LogisticRegression(solver=\"lbfgs\", multi_class=\"auto\"),\n",")\n"],"id":"f8ecdadb"},{"cell_type":"markdown","metadata":{"id":"90272282"},"source":["## Algorithm 3: Frequency band power"],"id":"90272282"},{"cell_type":"markdown","metadata":{"id":"0e91b732"},"source":["In this part, you will reimplement the frequency band power feature extraction method with baselining you developed earlier in this workshop, this time in the form of a Scikit-Learn pipeline that can be used for classification. Choose a fitting preprocessing paradigm(bandpass `SSVEP`, or `FilterBankSSVEP`) and implement a scikit-learn pipeline that applies baseline correction to each frequency band of each channel of each epoch. As a final step in the pipeline, apply a suiting classifier to classify the extracted features.\n","\n","**Hint**: You can implement [scikit-learn transformers](https://scikit-learn.org/stable/developers/develop.html)  with the following template:\n","```\n","class MyTransformer(BaseEstimator, TransformerMixin):\n","    \n","    def __init__(self, **params):\n","        ...\n","        \n","    def fit(self, X, y=None):\n","        ...\n","        return self\n","        \n","    def transform(self, X, y=None):\n","        ...\n","```\n","\n","or by plugging your own function into a [FunctionTransformer](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.FunctionTransformer.html)."],"id":"0e91b732"},{"cell_type":"code","execution_count":null,"metadata":{"id":"3fc17153"},"outputs":[],"source":["from sklearn.base import BaseEstimator, TransformerMixin\n","import numpy as np\n","from sklearn.preprocessing import FunctionTransformer\n","\n","paradigm_bandpower = FilterBankSSVEP(n_classes=n_classes, filters=filters, tmin=-3)\n","\n","def power_and_baseline(X, y=None, sfreq=128, tmin=-3, baseline=(-2.5, -.5)):\n","    # Cut baselining window\n","    baseline_start = int((baseline[0]-tmin)*sfreq)\n","    baseline_end = int((baseline[1]-tmin)*sfreq)\n","    baseline_period = X[:,:,baseline_start:baseline_end,:]\n","    # Cut stimulation window\n","    stim_start = max(0, int(-tmin*sfreq))\n","    stimulation_period = X[:,:,stim_start:,:]\n","    # Calculate baseline power and stimulation power\n","    baseline_power = np.mean(baseline_period**2, axis=(1,2))\n","    stimulation_power = np.mean(stimulation_period**2, axis=(1,2))\n","    # Divide stimulation power by baseline power\n","    return np.log(stimulation_power/baseline_power)\n","\n","pipelines_bandpower = dict()\n","pipelines_bandpower['power+logreg'] = make_pipeline(\n","    FunctionTransformer(power_and_baseline),\n","    LogisticRegression(solver=\"lbfgs\", multi_class=\"auto\"),\n",")"],"id":"3fc17153"},{"cell_type":"markdown","metadata":{"id":"b0a5b772"},"source":["## Evaluate algorithm performance\n","\n","You can run the following snippets to evaluate and compare the performance of your algorithms."],"id":"b0a5b772"},{"cell_type":"code","execution_count":null,"metadata":{"id":"b7970262"},"outputs":[],"source":["from moabb.evaluations import WithinSessionEvaluation\n","\n","evaluation_cca = WithinSessionEvaluation(\n","    paradigm=paradigm_cca,\n","    datasets=dataset,\n","    suffix=\"ssvep_workshop_cca\",\n","    overwrite=False\n",")\n","results_cca = evaluation_cca.process(pipelines_cca)\n","results_cca"],"id":"b7970262"},{"cell_type":"code","execution_count":null,"metadata":{"id":"302ed204"},"outputs":[],"source":["evaluation_rg = WithinSessionEvaluation(\n","    paradigm=paradigm_rg,\n","    datasets=dataset,\n","    suffix=\"ssvep_workshop_rg\",\n","    overwrite=False\n",")\n","results_rg = evaluation_rg.process(pipelines_rg)\n","results_rg"],"id":"302ed204"},{"cell_type":"code","execution_count":null,"metadata":{"id":"c89adf3f"},"outputs":[],"source":["evaluation_bandpower = WithinSessionEvaluation(\n","    paradigm=paradigm_bandpower,\n","    datasets=dataset,\n","    suffix=\"ssvep_workshop_bandpower\",\n","    overwrite=True\n",")\n","results_bandpower = evaluation_bandpower.process(pipelines_bandpower)\n","results_bandpower"],"id":"c89adf3f"},{"cell_type":"code","execution_count":null,"metadata":{"id":"187447dd"},"outputs":[],"source":["import seaborn as sns\n","import pandas as pd\n","\n","results = pd.concat([results_cca, results_rg, results_bandpower])\n","ax = sns.stripplot(data=results, y=\"score\", x=\"pipeline\", zorder=1, alpha=.5, palette=\"Set1\")\n","ax = sns.pointplot(data=results, y=\"score\", x=\"pipeline\" , palette=\"Set1\")\n","ax.set_ylabel(\"Accuracy\")\n","ax.axhline(1/n_classes)\n","_ = ax.set_ylim(0,1)"],"id":"187447dd"},{"cell_type":"markdown","metadata":{"id":"bae37539"},"source":["## References\n","\n","[2] Bin, G., Gao, X., Yan, Z., Hong, B., & Gao, S. (2009). An online multi-channel SSVEP-based brain-computer interface using a canonical correlation analysis method. Journal of neural engineering, 6(4), 046002. https://doi.org/10.1088/1741-2560/6/4/046002\n","\n","[3] Kalunga, E. K., Chevallier, S., Barthélemy, Q., Djouani, K., Monacelli, E., & Hamam, Y. (2016). Online SSVEP-based BCI using Riemannian geometry. Neurocomputing, 191, 55-68. https://doi.org/10.1016/j.neucom.2016.01.007"],"id":"bae37539"}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.5"},"colab":{"provenance":[{"file_id":"1_wOm1QVRRhg5u_h7ZXhSl6vgnWi1XUFJ","timestamp":1697638927123},{"file_id":"https://github.com/NeuroTech-Leuven/ssvep-workshop/blob/main/notebooks/0_verify_installation.ipynb","timestamp":1697466640027}],"toc_visible":true}},"nbformat":4,"nbformat_minor":5}
